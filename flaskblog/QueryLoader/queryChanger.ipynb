{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk.corpus import wordnet\n",
    "stop_words = set(stopwords.words('english')) \n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import unicodedata\n",
    "import functools\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isSynom(word1,word2):\n",
    "    for syn in wordnet.synsets(word1):\n",
    "        if word2 in syn.lemma_names():\n",
    "            return True\n",
    "    return False\n",
    "isSynom('sd','sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sum', 'total', 'totality', 'aggregate', 'sum', 'amount', 'total', 'total', 'number', 'add_up', 'come', 'amount', 'total', 'tot', 'tot_up', 'sum', 'sum_up', 'summate', 'tote_up', 'add', 'add_together', 'tally', 'add_up', 'total', 'entire', 'full', 'total', 'full', 'total']\n"
     ]
    }
   ],
   "source": [
    "def synonyms(word):\n",
    "    synonyms=[]\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "    return synonyms\n",
    "print(synonyms('total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column:\n",
    "    def __init__(self, name='', type=None, equivalences=None):\n",
    "        self._name = name\n",
    "\n",
    "        if not type:\n",
    "            type = []\n",
    "        self._type = type\n",
    "\n",
    "        if not equivalences:\n",
    "            equivalences = []\n",
    "        self._equivalences = equivalences\n",
    "\n",
    "        self.primary = False\n",
    "        self.foreign = False\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def get_type(self):\n",
    "        return self._type\n",
    "\n",
    "    def add_type(self, type):\n",
    "        self.type.append(type)\n",
    "\n",
    "    @property\n",
    "    def equivalences(self):\n",
    "        return self._equivalences\n",
    "\n",
    "    def add_equivalence(self, equivalence):\n",
    "        self.equivalences.append(equivalence)\n",
    "\n",
    "    def is_equivalent(self, word):\n",
    "        if word in self.equivalences:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_primary(self):\n",
    "        return self.primary\n",
    "\n",
    "    def set_as_primary(self):\n",
    "        self.primary = True\n",
    "\n",
    "    def is_foreign(self):\n",
    "        return self.foreign\n",
    "\n",
    "    def set_as_foreign(self, references):\n",
    "        self.foreign = references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table:\n",
    "    def __init__(self, name='', columns=None, equivalences=None):\n",
    "        self._name = name\n",
    "\n",
    "        if not columns:\n",
    "            columns = []\n",
    "        self.columns = columns\n",
    "\n",
    "        if not equivalences:\n",
    "            equivalences = []\n",
    "        self.equivalences = equivalences\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @name.setter\n",
    "    def name(self, value):\n",
    "        self._name = value\n",
    "\n",
    "    def get_number_of_columns(self):\n",
    "        return len(self.columns)\n",
    "\n",
    "    def get_columns(self):\n",
    "        return self.columns\n",
    "\n",
    "    def get_column_by_name(self, column_name):\n",
    "        for column in self.columns:\n",
    "            if column.name == column_name:\n",
    "                return column\n",
    "\n",
    "    def add_column(self, column_name, column_type, column_equivalences):\n",
    "        self.columns.append(Column(column_name, column_type, column_equivalences))\n",
    "\n",
    "    def get_equivalences(self):\n",
    "        return self.equivalences\n",
    "\n",
    "    def add_equivalence(self, equivalence):\n",
    "        self.equivalences.append(equivalence)\n",
    "\n",
    "    def is_equivalent(self, word):\n",
    "        if word in self.equivalences:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_primary_keys(self):\n",
    "        primary_keys = []\n",
    "        for column in self.columns:\n",
    "            if column.is_primary():\n",
    "                primary_keys.append(column)\n",
    "        return primary_keys\n",
    "\n",
    "    def get_primary_key_names(self):\n",
    "        primary_keys = []\n",
    "        for column in self.columns:\n",
    "            if column.is_primary():\n",
    "                primary_keys.append(column.name)\n",
    "        return primary_keys\n",
    "\n",
    "    def add_primary_key(self, primary_key_column):\n",
    "        for column in self.columns:\n",
    "            if column.name == primary_key_column:\n",
    "                column.set_as_primary()\n",
    "\n",
    "    def get_foreign_keys(self):\n",
    "        foreign_keys = []\n",
    "        for column in self.columns:\n",
    "            if column.is_foreign():\n",
    "                foreign_keys.append(column)\n",
    "        return foreign_keys\n",
    "\n",
    "    def get_foreign_key_names(self):\n",
    "        foreign_keys = []\n",
    "        for column in self.columns:\n",
    "            if column.is_foreign():\n",
    "                foreign_keys.append(column.name)\n",
    "        return foreign_keys\n",
    "\n",
    "    def add_foreign_key(self, column_name, foreign_table, foreign_column):\n",
    "        for column in self.columns:\n",
    "            if column.name == column_name:\n",
    "                column.set_as_foreign({'foreign_table': foreign_table, 'foreign_column': foreign_column})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tables = []\n",
    "        self.thesaurus_object = None\n",
    "\n",
    "    def set_thesaurus(self, thesaurus):\n",
    "        self.thesaurus_object = thesaurus\n",
    "\n",
    "    def get_number_of_tables(self):\n",
    "        return len(self.tables)\n",
    "\n",
    "    def get_tables(self):\n",
    "        return self.tables\n",
    "\n",
    "    def get_column_with_this_name(self, name):\n",
    "        for table in self.tables:\n",
    "            for column in table.get_columns():\n",
    "                if column.name == name:\n",
    "                    return column\n",
    "\n",
    "    def get_table_by_name(self, table_name):\n",
    "        for table in self.tables:\n",
    "            if table.name == table_name:\n",
    "                return table\n",
    "\n",
    "    def get_tables_into_dictionary(self):\n",
    "        data = {}\n",
    "        for table in self.tables:\n",
    "            data[table.name] = []\n",
    "            for column in table.get_columns():\n",
    "                data[table.name].append(column.name)\n",
    "        return data\n",
    "\n",
    "    def get_primary_keys_by_table(self):\n",
    "        data = {}\n",
    "        for table in self.tables:\n",
    "            data[table.name] = table.get_primary_keys()\n",
    "        return data\n",
    "\n",
    "    def get_foreign_keys_by_table(self):\n",
    "        data = {}\n",
    "        for table in self.tables:\n",
    "            data[table.name] = table.get_foreign_keys()\n",
    "        return data\n",
    "\n",
    "    def get_primary_keys_of_table(self, table_name):\n",
    "        for table in self.tables:\n",
    "            if table.name == table_name:\n",
    "                return table.get_primary_keys()\n",
    "\n",
    "    def get_primary_key_names_of_table(self, table_name):\n",
    "        for table in self.tables:\n",
    "            if table.name == table_name:\n",
    "                return table.get_primary_key_names()\n",
    "\n",
    "    def get_foreign_keys_of_table(self, table_name):\n",
    "        for table in self.tables:\n",
    "            if table.name == table_name:\n",
    "                return table.get_foreign_keys()\n",
    "\n",
    "    def get_foreign_key_names_of_table(self, table_name):\n",
    "        for table in self.tables:\n",
    "            if table.name == table_name:\n",
    "                return table.get_foreign_key_names()\n",
    "\n",
    "    def add_table(self, table):\n",
    "        self.tables.append(table)\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_path(path):\n",
    "        cwd = os.path.dirname(__file__)\n",
    "        filename = os.path.join(cwd, path)\n",
    "        return filename\n",
    "\n",
    "    def load(self, path):\n",
    "        with open(path) as f:\n",
    "            content = f.read()\n",
    "            tables_string = [p.split(';')[0] for p in content.split('CREATE') if ';' in p]\n",
    "            for table_string in tables_string:\n",
    "                if 'TABLE' in table_string:\n",
    "                    table = self.create_table(table_string)\n",
    "                    self.add_table(table)\n",
    "            alter_tables_string = [p.split(';')[0] for p in content.split('ALTER') if ';' in p]\n",
    "            for alter_table_string in alter_tables_string:\n",
    "                if 'TABLE' in alter_table_string:\n",
    "                    self.alter_table(alter_table_string)\n",
    "\n",
    "    def predict_type(self, string):\n",
    "        if 'int' in string.lower():\n",
    "            return 'int'\n",
    "        elif 'char' in string.lower() or 'text' in string.lower():\n",
    "            return 'string'\n",
    "        elif 'date' in string.lower():\n",
    "            return 'date'\n",
    "        else:\n",
    "            return 'unknow'\n",
    "\n",
    "    def create_table(self, table_string):\n",
    "        lines = table_string.split(\"\\n\")\n",
    "        table = Table()\n",
    "        for line in lines:\n",
    "            if 'TABLE' in line:\n",
    "                table_name = re.search(\"`(\\w+)`\", line)\n",
    "                table.name = table_name.group(1)\n",
    "                if self.thesaurus_object is not None:\n",
    "                    table.equivalences = self.thesaurus_object.get_synonyms_of_a_word(table.name)\n",
    "            elif 'PRIMARY KEY' in line:\n",
    "                primary_key_columns = re.findall(\"`(\\w+)`\", line)\n",
    "                for primary_key_column in primary_key_columns:\n",
    "                    table.add_primary_key(primary_key_column)\n",
    "            else:\n",
    "                column_name = re.search(\"`(\\w+)`\", line)\n",
    "                if column_name is not None:\n",
    "                    column_type = self.predict_type(line)\n",
    "                    if self.thesaurus_object is not None:\n",
    "                        equivalences = self.thesaurus_object.get_synonyms_of_a_word(column_name.group(1))\n",
    "                    else:\n",
    "                        equivalences = []\n",
    "                    table.add_column(column_name.group(1), column_type, equivalences)\n",
    "        return table\n",
    "\n",
    "    def alter_table(self, alter_string):\n",
    "        lines = alter_string.replace('\\n', ' ').split(';')\n",
    "        for line in lines:\n",
    "            if 'PRIMARY KEY' in line:\n",
    "                table_name = re.search(\"TABLE `(\\w+)`\", line).group(1)\n",
    "                table = self.get_table_by_name(table_name)\n",
    "                primary_key_columns = re.findall(\"PRIMARY KEY \\(`(\\w+)`\\)\", line)\n",
    "                for primary_key_column in primary_key_columns:\n",
    "                    table.add_primary_key(primary_key_column)\n",
    "            elif 'FOREIGN KEY' in line:\n",
    "                table_name = re.search(\"TABLE `(\\w+)`\", line).group(1)\n",
    "                table = self.get_table_by_name(table_name)\n",
    "                foreign_keys_list = re.findall(\"FOREIGN KEY \\(`(\\w+)`\\) REFERENCES `(\\w+)` \\(`(\\w+)`\\)\", line)\n",
    "                for column, foreign_table, foreign_column in foreign_keys_list:\n",
    "                    table.add_foreign_key(column, foreign_table, foreign_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-7-28df72d749f2>, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-28df72d749f2>\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    for j in range (i,len(word_dict)):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def changeQuery(database_path,line):\n",
    "    database =Database()\n",
    "    database.load(database_path)\n",
    "    dict_database = database.get_tables_into_dictionary()\n",
    "    data = {'sentence':'', 'count':'','select':'', 'from':'','where': ''}\n",
    "    data['sentence'] =line\n",
    "    words = word_tokenize(line)\n",
    "    word_dict=nltk.pos_tag(words)\n",
    "    print(word_dict)\n",
    "    for i in range(len(word_dict)):\n",
    "        if (word_dict[i][-1]== 'WRB'):\n",
    "            print('count procedding')\n",
    "            for j in range (i,len(word_dict)):\n",
    "                    if (word_dict[j][-1][0]== 'N'):\n",
    "                        draft = word_dict[j][0]\n",
    "                        if(database.get_column_with_this_name(draft)!= None):\n",
    "                            data['count'] = draft\n",
    "                        elif(isSynom(database.get_column_with_this_name(draft).name,draft)):\n",
    "                            data['count'] = database.get_column_with_this_name(draft)\n",
    "                        break\n",
    "            break\n",
    "        if ((word_dict[i][-1][0]== 'W') and (data['count'] == '')):\n",
    "            print('select procedding...')\n",
    "            for j in range (i,len(word_dict)):\n",
    "                    if (word_dict[j][-1][0]== 'N'):\n",
    "                        draft = word_dict[j][0]\n",
    "                        if(database.get_column_with_this_name(draft)!= None):\n",
    "                            data['select'] = draft\n",
    "                        elif(isSynom(database.get_column_with_this_name(draft).name,draft)):\n",
    "                            data['select'] = database.get_column_with_this_name(draft)\n",
    "                        break\n",
    "            break\n",
    "    for i in range(len(word_dict)):\n",
    "        if (word_dict[i][-1][0]== 'N') or (word_dict[i][-1]== 'JJR'):\n",
    "            if (word_dict[i][0]) in dict_database.keys():\n",
    "                data['from']=word_dict[i][0]\n",
    "            else:\n",
    "                for key in dict_database.keys():\n",
    "                    if isSynom(key,word_dict[i][0]):\n",
    "                        data['from']= key\n",
    "                                    \n",
    "                \n",
    "    for i in range(len(word_dict)):\n",
    "        data['where']=[]\n",
    "        if (word_dict[i][-1][0]== 'N') or (word_dict[i][-1]== 'JJR'):\n",
    "            if(database.get_column_with_this_name(word_dict[i][0])!= None):\n",
    "                if data['select'] != word_dict[i][0]:\n",
    "                    data['where'].append(word_dict[i][0])\n",
    "                     for j in range (i,len(word_dict)):\n",
    "                            if (word_dict[i][-1])=''\n",
    "                    \n",
    "                \n",
    "    \n",
    "    sql ='count '+data['count']+' Select '+data['select']+'\\n'+' from '+data['from']+'\\n'+ ' where '+data['where']\n",
    "    return sql\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'changeQuery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bd54524419ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchangeQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'database_store/city.sql'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'what many the id of the city which name is jaffna'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'changeQuery' is not defined"
     ]
    }
   ],
   "source": [
    "print(changeQuery('database_store/city.sql','what many the id of the city which name is jaffna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(database,phrase):\n",
    "    table =[]\n",
    "    dict_database = database.get_tables_into_dictionary()\n",
    "    words = word_tokenize(phrase)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    for word in filtered_words:\n",
    "        if word in dict_database.keys():\n",
    "            table.append(word)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictColumn(database,table_name,phrase):\n",
    "    columns =[]\n",
    "    dict_database = database.get_tables_into_dictionary()\n",
    "    #print(dict_database)\n",
    "    #print(table_name)\n",
    "    words = word_tokenize(phrase)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    word_dict=nltk.pos_tag(filtered_words)\n",
    "    #print(word_dict)\n",
    "    table = dict_database[table_name]\n",
    "    for j in range (len(word_dict)):\n",
    "        if (word_dict[j][-1][0]== 'N') or (word_dict[j][-1][0]== 'J'):\n",
    "            sample = word_dict[j][0]\n",
    "            #print(sample)\n",
    "            for name in table:\n",
    "                if name == sample:\n",
    "                    columns.append(name)\n",
    "                elif isSynom(sample,name):\n",
    "                    columns.append(name)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumElements(dict):\n",
    "    c=0\n",
    "    for item in dict.keys():\n",
    "        c=c+1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsingPhrase(database,phrase):\n",
    "    tables=get_table(database,phrase)\n",
    "    table=tables[0]\n",
    "    words = word_tokenize(phrase)\n",
    "    im_words={}\n",
    "    for i in range(len(words)):\n",
    "        tag = nltk.tag.pos_tag([words[i]])\n",
    "        if tag[0][-1][0]=='W':\n",
    "            im_words[words[i]]=i\n",
    "        if words[i]== table:\n",
    "            im_words['table'] =i\n",
    "    return im_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectColumnParser(database,phrase):\n",
    "    data={'select':'','count':'','max':'','min':'','sum':'','distinct':'','error':'','avg':''}\n",
    "    tables=get_table(database,phrase)\n",
    "    table=''\n",
    "    #print(tables)\n",
    "    if(len(tables) ==0):\n",
    "        print('you have no tables in your phrase')\n",
    "    elif(len(tables) ==1):\n",
    "        table=tables[0]\n",
    "    if table != '':\n",
    "        #print(table)\n",
    "        columns = predictColumn(database,table,phrase)\n",
    "        #print(columns)\n",
    "        words = word_tokenize(phrase)\n",
    "        im_words=parsingPhrase(database,phrase)\n",
    "        for i in range(len(words)):\n",
    "            if words[i] in synonyms('count') and (words[i] not in columns):\n",
    "                for j in range(i,int(im_words['table'])):\n",
    "                    if words[j] in columns:\n",
    "                        data['count']= words[j]\n",
    "                        break\n",
    "                    else:\n",
    "                        data['count']= '*'\n",
    "                    \n",
    "            elif words[i] in synonyms('total') and (words[i] not in columns):\n",
    "                for j in range(i,int(im_words['table'])):\n",
    "                    if words[j] in columns:\n",
    "                        data['sum']= words[j]\n",
    "                        break\n",
    "                    else:\n",
    "                        data['sum']= '*'\n",
    "            if words[i] in synonyms('maximum') and (words[i] not in columns):\n",
    "                for j in range(i,int(im_words['table'])):\n",
    "                    if words[j] in columns:\n",
    "                        data['max']= words[j]\n",
    "                        break\n",
    "                    else:\n",
    "                        data['max']= '*'\n",
    "            if words[i] in synonyms('minimum') and (words[i] not in columns):\n",
    "                for j in range(i,int(im_words['table'])):\n",
    "                    if words[j] in columns:\n",
    "                        data['min']= words[j]\n",
    "                        break\n",
    "                    else:\n",
    "                        data['min']= '*'\n",
    "            if words[i] in synonyms('distinct') and (words[i] not in columns):\n",
    "                for j in range(i,int(im_words['table'])):\n",
    "                    if words[j] in columns:\n",
    "                        data['distinct']= words[j]\n",
    "                        break\n",
    "                    else:\n",
    "                        data['distinct']= '*'\n",
    "            if words[i] in synonyms('average') and (words[i] not in columns):\n",
    "                for j in range(i,int(im_words['table'])):\n",
    "                    if words[j] in columns:\n",
    "                        data['avg']= words[j]\n",
    "                        break\n",
    "                    else:\n",
    "                        data['avg']= '*'\n",
    "        print(data)\n",
    "        for word in words:\n",
    "            if im_words['table']:\n",
    "                index_of_the_table= im_words.get('table')\n",
    "                if sumElements(im_words)==2:\n",
    "                    for item in im_words:\n",
    "                        item.value()\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "database=Database()\n",
    "database.load('database_store/city.sql')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectParser(Thread):\n",
    "    def __init__(self, columns_of_select, tables_of_from, phrase, database):\n",
    "        Thread.__init__(self)\n",
    "        self.select_objects = []\n",
    "        self.columns_of_select = columns_of_select\n",
    "        self.tables_of_from = tables_of_from\n",
    "        self.phrase = phrase\n",
    "        self.count_keywords =str('number, how many, count')\n",
    "        self.sum_keywords =str('sum, total').split(',')\n",
    "        self.average_keywords = str('average, avg, Average').split(',')\n",
    "        self.max_keywords =str('maximum, highest, max').split(',')\n",
    "        self.min_keywords =str('minimum, lowest, min').split(',')\n",
    "        self.distinct_keywords =str('distinct, different, distinctive, distinctly, unique').split(',')\n",
    "        self.database_object = database\n",
    "        self.database_dico = self.database_object.get_tables_into_dictionary()\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    def get_tables_of_column(self, column):\n",
    "        tmp_table = []\n",
    "        for table in self.database_dico:\n",
    "            if column in self.database_dico[table]:\n",
    "                tmp_table.append(table)\n",
    "        return tmp_table\n",
    "\n",
    "    def get_column_name_with_alias_table(self, column, table_of_from):\n",
    "        one_table_of_column = self.get_tables_of_column(column)[0]\n",
    "        tables_of_column = self.get_tables_of_column(column)\n",
    "        if table_of_from in tables_of_column:\n",
    "            return str(table_of_from) + '.' + str(column)\n",
    "        else:\n",
    "            return str(one_table_of_column) + '.' + str(column)\n",
    "\n",
    "    def uniquify(self, list):\n",
    "        already = []\n",
    "        for element in list:\n",
    "            if element not in already:\n",
    "                already.append(element)\n",
    "        return already\n",
    "\n",
    "    def run(self):\n",
    "        for table_of_from in self.tables_of_from:  # for each query\n",
    "            self.select_object = Select()\n",
    "            is_count = False\n",
    "            self.columns_of_select = self.uniquify(self.columns_of_select)\n",
    "            number_of_select_column = len(self.columns_of_select)\n",
    "\n",
    "            if number_of_select_column == 0:\n",
    "                select_type = []\n",
    "                for count_keyword in self.count_keywords:\n",
    "                    # if count_keyword in (word.lower() for word in self.phrase):\n",
    "                    # so that it matches multiple words too in keyword synonymn in .lang rather than just single word for COUNT\n",
    "                    # (e.g. QUERY-> \"how many city there are in which the employe name is aman ?\" )\n",
    "                    lower_self_phrase = ' '.join(word.lower() for word in self.phrase)\n",
    "                    if count_keyword in lower_self_phrase:\n",
    "                        select_type.append('COUNT')\n",
    "\n",
    "                self.select_object.add_column(None, self.uniquify(select_type))\n",
    "            else:\n",
    "                select_phrases = []\n",
    "                previous_index = 0\n",
    "\n",
    "                for i in range(0, len(self.phrase)):\n",
    "                    for column_name in self.columns_of_select:\n",
    "                        if (self.phrase[i] == column_name) or (\n",
    "                                    self.phrase[i] in self.database_object.get_column_with_this_name(column_name).equivalences):\n",
    "                            select_phrases.append(self.phrase[previous_index:i + 1])\n",
    "                            previous_index = i + 1\n",
    "\n",
    "                select_phrases.append(self.phrase[previous_index:])\n",
    "\n",
    "                for i in range(0, len(select_phrases)):  # for each select phrase (i.e. column processing)\n",
    "                    select_type = []\n",
    "\n",
    "                    phrase = [word.lower() for word in select_phrases[i]]\n",
    "\n",
    "                    for keyword in self.average_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type.append('AVG')\n",
    "                    for keyword in self.count_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type.append('COUNT')\n",
    "                    for keyword in self.max_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type.append('MAX')\n",
    "                    for keyword in self.min_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type.append('MIN')\n",
    "                    for keyword in self.sum_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type.append('SUM')\n",
    "                    for keyword in self.distinct_keywords:\n",
    "                        if keyword in phrase:\n",
    "                            select_type.append('DISTINCT')\n",
    "\n",
    "                    if (i != len(select_phrases) - 1):\n",
    "                        column = self.get_column_name_with_alias_table(self.columns_of_select[i], table_of_from)\n",
    "                        self.select_object.add_column(column, self.uniquify(select_type))\n",
    "\n",
    "            self.select_objects.append(self.select_object)\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.select_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhereParser(Thread):\n",
    "    def __init__(self, phrases, tables_of_from, columns_of_values_of_where, count_keywords, sum_keywords,\n",
    "                 average_keywords, max_keywords, min_keywords, greater_keywords, less_keywords, between_keywords,\n",
    "                 negation_keywords, junction_keywords, disjunction_keywords, like_keywords, distinct_keywords,\n",
    "                 database_dico, database_object):\n",
    "        Thread.__init__(self)\n",
    "        self.where_objects = []\n",
    "        self.phrases = phrases\n",
    "        self.tables_of_from = tables_of_from\n",
    "        self.columns_of_values_of_where = columns_of_values_of_where\n",
    "        self.count_keywords = count_keywords\n",
    "        self.sum_keywords = sum_keywords\n",
    "        self.average_keywords = average_keywords\n",
    "        self.max_keywords = max_keywords\n",
    "        self.min_keywords = min_keywords\n",
    "        self.greater_keywords = greater_keywords\n",
    "        self.less_keywords = less_keywords\n",
    "        self.between_keywords = between_keywords\n",
    "        self.negation_keywords = negation_keywords\n",
    "        self.junction_keywords = junction_keywords\n",
    "        self.disjunction_keywords = disjunction_keywords\n",
    "        self.like_keywords = like_keywords\n",
    "        self.distinct_keywords = distinct_keywords\n",
    "        self.database_dico = database_dico\n",
    "        self.database_object = database_object\n",
    "\n",
    "    def get_tables_of_column(self, column):\n",
    "        tmp_table = []\n",
    "        for table in self.database_dico:\n",
    "            if column in self.database_dico[table]:\n",
    "                tmp_table.append(table)\n",
    "        return tmp_table\n",
    "\n",
    "    def get_column_name_with_alias_table(self, column, table_of_from):\n",
    "        one_table_of_column = self.get_tables_of_column(column)[0]\n",
    "        tables_of_column = self.get_tables_of_column(column)\n",
    "        if table_of_from in tables_of_column:\n",
    "            return str(table_of_from) + '.' + str(column)\n",
    "        else:\n",
    "            return str(one_table_of_column) + '.' + str(column)\n",
    "\n",
    "    def intersect(self, a, b):\n",
    "        return list(set(a) & set(b))\n",
    "\n",
    "    def predict_operation_type(self, previous_column_offset, current_column_offset):\n",
    "        interval_offset = list(range(previous_column_offset, current_column_offset))\n",
    "        if (len(self.intersect(interval_offset, self.count_keyword_offset)) >= 1):\n",
    "            return 'COUNT'\n",
    "        elif (len(self.intersect(interval_offset, self.sum_keyword_offset)) >= 1):\n",
    "            return 'SUM'\n",
    "        elif (len(self.intersect(interval_offset, self.average_keyword_offset)) >= 1):\n",
    "            return 'AVG'\n",
    "        elif (len(self.intersect(interval_offset, self.max_keyword_offset)) >= 1):\n",
    "            return 'MAX'\n",
    "        elif (len(self.intersect(interval_offset, self.min_keyword_offset)) >= 1):\n",
    "            return 'MIN'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def predict_operator(self, current_column_offset, next_column_offset):\n",
    "        interval_offset = list(range(current_column_offset, next_column_offset))\n",
    "\n",
    "        if (len(self.intersect(interval_offset, self.negation_keyword_offset)) >= 1) and (\n",
    "                    len(self.intersect(interval_offset, self.greater_keyword_offset)) >= 1):\n",
    "            return '<'\n",
    "        elif (len(self.intersect(interval_offset, self.negation_keyword_offset)) >= 1) and (\n",
    "                    len(self.intersect(interval_offset, self.less_keyword_offset)) >= 1):\n",
    "            return '>'\n",
    "        if (len(self.intersect(interval_offset, self.less_keyword_offset)) >= 1):\n",
    "            return '<'\n",
    "        elif (len(self.intersect(interval_offset, self.greater_keyword_offset)) >= 1):\n",
    "            return '>'\n",
    "        elif (len(self.intersect(interval_offset, self.between_keyword_offset)) >= 1):\n",
    "            return 'BETWEEN'\n",
    "        elif (len(self.intersect(interval_offset, self.negation_keyword_offset)) >= 1):\n",
    "            return '!='\n",
    "        elif (len(self.intersect(interval_offset, self.like_keyword_offset)) >= 1):\n",
    "            return 'LIKE'\n",
    "        else:\n",
    "            return '='\n",
    "\n",
    "    def predict_junction(self, previous_column_offset, current_column_offset):\n",
    "        interval_offset = list(range(previous_column_offset, current_column_offset))\n",
    "        junction = 'AND'\n",
    "        if (len(self.intersect(interval_offset, self.disjunction_keyword_offset)) >= 1):\n",
    "            return 'OR'\n",
    "        elif (len(self.intersect(interval_offset, self.junction_keyword_offset)) >= 1):\n",
    "            return 'AND'\n",
    "\n",
    "        first_encountered_junction_offset = -1\n",
    "        first_encountered_disjunction_offset = -1\n",
    "\n",
    "        for offset in self.junction_keyword_offset:\n",
    "            if offset >= current_column_offset:\n",
    "                first_encountered_junction_offset = offset\n",
    "                break\n",
    "\n",
    "        for offset in self.disjunction_keyword_offset:\n",
    "            if offset >= current_column_offset:\n",
    "                first_encountered_disjunction_offset = offset\n",
    "                break\n",
    "\n",
    "        if first_encountered_junction_offset >= first_encountered_disjunction_offset:\n",
    "            return 'AND'\n",
    "        else:\n",
    "            return 'OR'\n",
    "\n",
    "    def uniquify(self, list):\n",
    "        already = []\n",
    "        for element in list:\n",
    "            if element not in already:\n",
    "                already.append(element)\n",
    "        return already\n",
    "\n",
    "    def run(self):\n",
    "        number_of_where_columns = 0\n",
    "        columns_of_where = []\n",
    "        offset_of = {}\n",
    "        column_offset = []\n",
    "        self.count_keyword_offset = []\n",
    "        self.sum_keyword_offset = []\n",
    "        self.average_keyword_offset = []\n",
    "        self.max_keyword_offset = []\n",
    "        self.min_keyword_offset = []\n",
    "        self.greater_keyword_offset = []\n",
    "        self.less_keyword_offset = []\n",
    "        self.between_keyword_offset = []\n",
    "        self.junction_keyword_offset = []\n",
    "        self.disjunction_keyword_offset = []\n",
    "        self.negation_keyword_offset = []\n",
    "        self.like_keyword_offset = []\n",
    "\n",
    "        for phrase in self.phrases:\n",
    "            phrase_offset_string = ''\n",
    "            for i in range(0, len(phrase)):\n",
    "                for table_name in self.database_dico:\n",
    "                    columns = self.database_object.get_table_by_name(table_name).get_columns()\n",
    "                    for column in columns:\n",
    "                        if (phrase[i] == column.name) or (phrase[i] in column.equivalences):\n",
    "                            number_of_where_columns += 1\n",
    "                            columns_of_where.append(column.name)\n",
    "                            offset_of[phrase[i]] = i\n",
    "                            column_offset.append(i)\n",
    "                            break\n",
    "                    else:\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "                phrase_keyword = str(phrase[i]).lower()  # for robust keyword matching\n",
    "                phrase_offset_string += phrase_keyword + \" \"\n",
    "\n",
    "                for keyword in self.count_keywords:\n",
    "                    if keyword in phrase_offset_string :    # before the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.count_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.sum_keywords:\n",
    "                    if keyword in phrase_offset_string :    # before the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.sum_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.average_keywords:\n",
    "                    if keyword in phrase_offset_string :    # before the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.average_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.max_keywords:\n",
    "                    if keyword in phrase_offset_string :    # before the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.max_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.min_keywords:\n",
    "                    if keyword in phrase_offset_string :    # before the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.min_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.greater_keywords:\n",
    "                    if keyword in phrase_offset_string :    # after the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.greater_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.less_keywords:\n",
    "                    if keyword in phrase_offset_string :    # after the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.less_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.between_keywords:\n",
    "                    if keyword in phrase_offset_string :    # after the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.between_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.junction_keywords:\n",
    "                    if keyword in phrase_offset_string :    # after the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.junction_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.disjunction_keywords:\n",
    "                    if keyword in phrase_offset_string :    # after the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.disjunction_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.negation_keywords:\n",
    "                    if keyword in phrase_offset_string :\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.negation_keyword_offset.append(i)\n",
    "\n",
    "                for keyword in self.like_keywords:\n",
    "                    if keyword in phrase_offset_string :    # after the column\n",
    "                        if (phrase_offset_string.find(keyword) + len(keyword) + 1 == len(phrase_offset_string) ) :\n",
    "                            self.like_keyword_offset.append(i)\n",
    "\n",
    "\n",
    "        for table_of_from in self.tables_of_from:\n",
    "            where_object = Where()\n",
    "            for i in range(0, len(column_offset)):\n",
    "                current = column_offset[i]\n",
    "\n",
    "                if i == 0:\n",
    "                    previous = 0\n",
    "                else:\n",
    "                    previous = column_offset[i - 1]\n",
    "\n",
    "                if i == (len(column_offset) - 1):\n",
    "                    _next = 999\n",
    "                else:\n",
    "                    _next = column_offset[i + 1]\n",
    "\n",
    "                junction = self.predict_junction(previous, current)\n",
    "                column = self.get_column_name_with_alias_table(columns_of_where[i], table_of_from)\n",
    "                operation_type = self.predict_operation_type(previous, current)\n",
    "\n",
    "                if len(self.columns_of_values_of_where) > i:\n",
    "                    value = self.columns_of_values_of_where[\n",
    "                        len(self.columns_of_values_of_where) - len(columns_of_where) + i]\n",
    "                else:\n",
    "                    value = 'OOV'  # Out Of Vocabulary: default value\n",
    "\n",
    "                operator = self.predict_operator(current, _next)\n",
    "                where_object.add_condition(junction, Condition(column, operation_type, operator, value))\n",
    "            self.where_objects.append(where_object)\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        return self.where_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsingSentence(database,phrase):\n",
    "    dict_database = database.get_tables_into_dictionary()\n",
    "    selectPhrase=''\n",
    "    fromPhrase=''\n",
    "    wherePhrase=''\n",
    "    table=[]\n",
    "    columns_of_select=[]\n",
    "    columns_of_where=[]\n",
    "    number_of_table=0\n",
    "    no_of_columns_select=0\n",
    "    number_of_where_column=0\n",
    "    last_table_position = 0\n",
    "    \n",
    "    columns_of_select=[]\n",
    "    input_for_finding_value = phrase.rstrip(string.punctuation.replace('\"', '').replace(\"'\", \"\"))\n",
    "    filter_list = [\",\", \"!\"]\n",
    "    for filter_element in filter_list:\n",
    "        input_for_finding_value = input_for_finding_value.replace(filter_element, \" \")\n",
    "    input_word_list = input_for_finding_value.split()\n",
    "    for i in range(0, len(input_word_list)):\n",
    "        for table_name in dict_database.keys() :\n",
    "            if (input_word_list[i] == table_name):\n",
    "                table.append(table_name)\n",
    "                if number_of_table== 0:\n",
    "                    select_phrase = input_word_list[:i]\n",
    "                    table.append(table_name)\n",
    "                    number_of_table += 1\n",
    "                    last_table_position = i\n",
    "            columns = database.get_table_by_name(table_name).get_columns()\n",
    "            for column in columns:\n",
    "                if (input_word_list[i] == column.name):\n",
    "                    if number_of_table == 0:\n",
    "                        columns_of_select.append(column.name)\n",
    "                        no_of_columns_select=no_of_columns_select+1\n",
    "                    else:\n",
    "                        if number_of_where_column == 0:\n",
    "                            from_phrase = input_word_list[len(select_phrase):last_table_position + 1]\n",
    "                        columns_of_where.append(column.name)\n",
    "                        number_of_where_column+=1\n",
    "                else:\n",
    "                    if (number_of_table != 0) and (number_of_where_column == 0) and (i == (len(input_word_list) - 1)):\n",
    "                        from_phrase=input_word_list[len(select_phrase):]\n",
    "    where_phrase = input_word_list[len(select_phrase) + len(from_phrase):]\n",
    "    if (number_of_select_column + number_of_table + number_of_where_column) == 0:\n",
    "        print(no_keywords_found)\n",
    "    \n",
    "    \n",
    "    print(select_phrase,from_phrase,where_phrase)\n",
    "    print(table)\n",
    "    print(columns_of_select)\n",
    "    print(last_table_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['give', 'the', 'number', 'of', 'id', 'in'] ['city'] ['where', 'the', 'cityName', 'is', 'colombo']\n",
      "['city', 'city']\n",
      "['id', 'id']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "parsingSentence( database,'give the number of id in city where the cityName is colombo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(('average, avg, Average').split(','))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
